{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZMBneLtMfFx"
      },
      "source": [
        "# Causal Inference on Bayesian Networks for AI for Search and Rescue\n",
        "## Author: Amanda Belden\n",
        "### Master's Thesis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJjeLolLupiK"
      },
      "source": [
        "I followed guidance from the following on how to build Bayesian Networks in python:\n",
        "Vidhi Chugh, \"PGM 3: Python Implementation,\" WiCDS, Medium, https://medium.com/wicds/pgm-3-python-implementation-541603f70f5f\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA2GnzQFO8ze"
      },
      "source": [
        "### Install Packages and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVpApUZVMkiX",
        "outputId": "8eeef6be-6fc6-428c-b0b5-98e946256960"
      },
      "outputs": [],
      "source": [
        "#pip install pgmpy\n",
        "#pip install feature_engine\n",
        "#pip install graphviz\n",
        "#pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xXlEeqhDzwt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pgmpy.estimators import HillClimbSearch, MaximumLikelihoodEstimator, BicScore\n",
        "from pgmpy.models import  BayesianNetwork\n",
        "from pgmpy.inference import VariableElimination, CausalInference\n",
        "\n",
        "from pgmpy.base import DAG\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BN - All Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import SAR data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar = pd.read_csv(\"df_sar.csv\")\n",
        "df_sar.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop the non-binned columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_categ = df_sar.copy()\n",
        "df_sar_categ = df_sar_categ.drop(columns=[\"Unnamed: 0\", \"INCIDENT NUMBER\", \"LOCATION FOUND LAT\", \"LOCATION FOUND LONG\", \"LOCATION FOUND ELEVATION\", \n",
        "                                    \"MIN TEMP DEG F\", \"MAX TEMP DEG F\", \"MIN SNOW DEPTH IN\", \"MAX SNOW DEPTH IN\", \n",
        "                                    \"NUMBER OF RANGERS INVOLVED\", 'LAST KNOWN POINT LAND CLASS', \"ACTIVITY\", \"ACTIONS\", \"ROUTE FOLLOWED\",\n",
        "                                    \"DETECTABILITY\", \"SITUATION\", \"CONTRIBUTING FACTOR\",\n",
        "                                    \"TOTAL HOURS ISD\", \"TOTAL HOURS DON\", 'Prop M Subjects', \"REASON FOR BEING LOST\",\n",
        "                                    \"Gender F Count\", \"Gender M Count\", \"Total Subjects\", \"Min Subject Age\", \"Max Subject Age\",\n",
        "                                    \"EQUIPMENT USED\", 'TECHNIQUE', 'start_time', 'TREATMENT PROVIDED BY RANGERS', 'TREATMENT PROVIDED BY OTHERS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_categ['INCIDENT REGION'] = df_sar_categ['INCIDENT REGION'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn = df_sar_categ.drop(columns=['SUBJECT STATE', 'SUBJECT COUNTRY', \n",
        "                                       'closed_day_of_week', 'closed_month', 'notif_year', 'closed_year', 'notif_day_of_week', \n",
        "                                       'notif_month', 'closed_time', 'notif_time', 'NA EQUIPMENT IND', 'LOCATION FOUND LAT BINNED', 'MIN TEMP BINNED', \n",
        "                                       'LOCATION FOUND LONG BINNED', 'LOCATION FOUND ELEVATION BINNED',\n",
        "                                       'MAX SNOW DEPTH BINNED', 'TOTAL HOURS DON BINNED', 'NA REASON IND', 'INCIDENT REGION ZONE', \n",
        "                                       'LAST KNOWN POINT COUNTY', 'INCIDENT COUNTY', 'Treatment Provided',\n",
        "                                       'NA TECHNIQUE IND', 'Gender M Count Binned', 'Gender F Count Binned', 'Min Subject Age Binned',\n",
        "                                       'LAST KNOWN POINT MAP NAME' ,'LAST KNOWN POINT STATE LAND NAME', 'LAST KNOWN POINT MUNICIPALITY',\n",
        "                                       'NA ACTION IND', 'NA ROUTE IND', 'NA CONTR FACTOR IND'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feature importance function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_feature_importance(df, n, sample_size):\n",
        "    all_variables = pd.DataFrame(list(df), columns=['Variables'])\n",
        "    all_variables['Total BIC'] = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        # Randomly select 10 columns from the DataFrame\n",
        "        sampled_columns = np.random.choice(df.columns, size=sample_size, replace=False)\n",
        "\n",
        "        # Create a new DataFrame containing only the sampled columns\n",
        "        sampled_df = df[sampled_columns].copy()\n",
        "\n",
        "        # train_X, test_X = train_test_split(sampled_df, test_size = 0.05, random_state = 1) \n",
        "        hc = HillClimbSearch(sampled_df, use_cache=True)\n",
        "        best_model = hc.estimate(scoring_method=BicScore(sampled_df), max_iter=2000000, show_progress=False);\n",
        "        edges = list(best_model.edges())\n",
        "        model = BayesianNetwork(edges)\n",
        "\n",
        "        bic = BicScore(sampled_df).score(model)\n",
        "        selected_variables = list(model)\n",
        "\n",
        "        # Filter the DataFrame based on the subset of variable names\n",
        "        subset_df = all_variables[all_variables['Variables'].isin(selected_variables)]\n",
        "\n",
        "        #Transform bic\n",
        "        if bic == 0:\n",
        "            bic_trans = 0\n",
        "        elif bic < 0:\n",
        "            bic_trans = 1 / abs(bic)\n",
        "        else:\n",
        "            bic_trans = bic\n",
        "\n",
        "        # Add a number to the 'Total BIC' column for the subset of variables\n",
        "        subset_df['Total BIC'] += bic_trans\n",
        "\n",
        "        # Update the original DataFrame with the modified subset DataFrame\n",
        "        all_variables.update(subset_df)\n",
        "\n",
        "# Sort the DataFrame by 'Total BIC' column\n",
        "    df_sorted = all_variables.sort_values(by='Total BIC')\n",
        "\n",
        "    # Plot the DataFrame\n",
        "    plt.figure(figsize=(10, 14))\n",
        "    plt.barh(df_sorted['Variables'], df_sorted['Total BIC'], color='skyblue')\n",
        "    plt.xlabel('Total of 1/ Abs(BIC)')\n",
        "    plt.ylabel('Variables')\n",
        "    plt.title('Feature Selection based on BIC Scores for Variables')\n",
        "    plt.ylim(-0.5, len(df_sorted) - 0.5)\n",
        "    # plt.xlim(-999999999, -99998999)\n",
        "    # plt.grid(axis='x')\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Selection Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_feature_selection(df, n, sample_size):\n",
        "    all_variables = pd.DataFrame(list(df), columns=['Variables'])\n",
        "    all_variables['Total BIC'] = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        # Randomly select 10 columns from the DataFrame\n",
        "        sampled_columns = np.random.choice(df.columns, size=20, replace=False)\n",
        "\n",
        "        # Create a new DataFrame containing only the sampled columns\n",
        "        sampled_df = df[sampled_columns].copy()\n",
        "\n",
        "        # train_X, test_X = train_test_split(sampled_df, test_size = 0.05, random_state = 1) \n",
        "        hc = HillClimbSearch(sampled_df, use_cache=True)\n",
        "        best_model = hc.estimate(scoring_method=BicScore(sampled_df), max_iter=2000000, show_progress=False);\n",
        "        edges = list(best_model.edges())\n",
        "        model = BayesianNetwork(edges)\n",
        "\n",
        "        bic = BicScore(sampled_df).score(model)\n",
        "        selected_variables = list(model)\n",
        "\n",
        "        # Filter the DataFrame based on the subset of variable names\n",
        "        subset_df = all_variables[all_variables['Variables'].isin(selected_variables)]\n",
        "        not_selected_variables = all_variables[~all_variables['Variables'].isin(selected_variables)]\n",
        "\n",
        "        # Add a number to the 'Total BIC' column for the subset of variables\n",
        "        subset_df['Total BIC'] += bic\n",
        "        not_selected_variables['Total BIC'] += -99999\n",
        "\n",
        "        # Update the original DataFrame with the modified subset DataFrame\n",
        "        all_variables.update(subset_df)\n",
        "        all_variables.update(not_selected_variables)\n",
        "    # Sort the DataFrame by 'Total BIC' column\n",
        "    df_sorted = all_variables.sort_values(by='Total BIC')\n",
        "\n",
        "    # Plot the DataFrame\n",
        "    plt.figure(figsize=(10, 14))\n",
        "    plt.barh(df_sorted['Variables'], df_sorted['Total BIC'], color='skyblue')\n",
        "    plt.xlabel('Total of BIC')\n",
        "    plt.ylabel('Variables')\n",
        "    plt.title('Feature Selection based on BIC Scores for Variables')\n",
        "    plt.ylim(-0.5, len(df_sorted) - 0.5)\n",
        "    # plt.xlim(-999999999, -99998999)\n",
        "    # plt.grid(axis='x')\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_full_cv(df, k=5):\n",
        "\n",
        "    # Initialize an empty list to store evaluation scores\n",
        "    models_and_scores = []\n",
        "\n",
        "    # Iterate over the folds\n",
        "    for i in range(k):\n",
        "        # Perform Bayesian network structure learning\n",
        "        hc = HillClimbSearch(df)\n",
        "        best_model = hc.estimate(scoring_method=BicScore(df), max_iter=2000000, show_progress=False)\n",
        "        \n",
        "        # Create the Bayesian network model\n",
        "        edges = list(best_model.edges())\n",
        "        model = BayesianNetwork(edges)\n",
        "        \n",
        "        # Evaluate the model on the test set (you need to implement your own evaluation method)\n",
        "        score = BicScore(df).score(model)\n",
        "        # Store the model and its BIC score\n",
        "        models_and_scores.append((model, score))\n",
        "\n",
        "    score_list = [x[1] for x in models_and_scores]\n",
        "    average_score = np.mean(score_list)\n",
        "    print(\"Average BIC score:\", average_score)\n",
        "    return models_and_scores\n",
        "\n",
        "# score_list = [x[1] for x in models_and_scores]\n",
        "# print(\"List of scores: \", score_list)\n",
        "\n",
        "# best_score = score_list[1]\n",
        "\n",
        "# model_list = [x[0] for x in models_and_scores]\n",
        "# best_model = model_list[1]\n",
        "# # print(\"Best model edges:\", best_model.edges())\n",
        "# print(\"Best model BIC score:\", best_score)\n",
        "\n",
        "# # Compute the average score across all folds\n",
        "# average_score = np.mean(score_list)\n",
        "# print(\"Average score:\", average_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start with full dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check_feature_selection(df_sar_bn, 150, 20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove least important (bottom) 10 variables: 'start_day_of_week', 'start_year', 'Patrol Bicycle IND', 'Aircraft ACTIVITY IND', 'Chainsaw ACTIVITY IND', 'Evacuation by animal IND', 'Discarded equipment ACTION IND', 'Stranded ACTIVITY IND', 'Biking ACTIVITY IND', 'Flood Victim ACTIVITY IND'\n",
        "\n",
        "Check new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn2 = df_sar_bn.copy()\n",
        "df_sar_bn2 = df_sar_bn2.drop(columns=['start_day_of_week', 'start_year', 'Patrol Bicycle IND', 'Aircraft ACTIVITY IND', 'Chainsaw ACTIVITY IND', \n",
        "                                      'Evacuation by animal IND', 'Discarded equipment ACTION IND', 'Stranded ACTIVITY IND', 'Biking ACTIVITY IND', \n",
        "                                      'Flood Victim ACTIVITY IND'])\n",
        "\n",
        "# check_feature_selection(df_sar_bn2, 150, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# models_and_scores2 = check_full_cv(df_sar_bn2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove least important (bottom) five variables: 'Horseback riding ACTIVITY IND', 'Natural clearing ROUTE IND', 'Weather', 'Visual Sighting from Air DETECT IND', 'TOTAL HOURS ISD BINNED'\n",
        "Check new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn3 = df_sar_bn2.copy()\n",
        "df_sar_bn3 = df_sar_bn3.drop(columns=['Horseback riding ACTIVITY IND', 'Natural clearing ROUTE IND',\n",
        "                                      'Visual Sighting from Air DETECT IND', 'TOTAL HOURS ISD BINNED'])\n",
        "\n",
        "# check_feature_selection(df_sar_bn3, 150, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# models_and_scores3 = check_full_cv(df_sar_bn3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove least important (bottom) five variables: 'Natural clearing ROUTE IND', 'Horseback riding ACTIVITY IND', 'Visual Sighting from Air DETECT IND', \n",
        "                                      'Camping ACTIVITY IND', 'Weather'\n",
        "\n",
        "Check new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn4 = df_sar_bn3.copy()\n",
        "df_sar_bn4 = df_sar_bn4.drop(columns=['Toward landmark ROUTE IND', 'Toward civilization ROUTE IND', 'Max Subject Age Binned', \n",
        "                                      'Camping ACTIVITY IND', 'Ice rescue gear IND'])\n",
        "\n",
        "# check_feature_selection(df_sar_bn4, 150, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# models_and_scores4 = check_full_cv(df_sar_bn4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# score_list = [x[1] for x in models_and_scores4]\n",
        "# print(score_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model not changing much. Move to pruning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hc = HillClimbSearch(df_sar_bn4, use_cache=True)\n",
        "best_model = hc.estimate(scoring_method=BicScore(df_sar_bn4), max_iter=2000000, show_progress=False)\n",
        "edges = list(best_model.edges())\n",
        "model = BayesianNetwork(edges)\n",
        "\n",
        "print(edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BicScore(df_sar_bn4).score(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# nx.draw(model, with_labels=True)\n",
        "plt.figure(figsize=(40, 45))\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, pos=pos, with_labels=True, node_size=3000, width=2, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='silver', font_color='black', connectionstyle='arc3,rad=0.2')\n",
        "plt.savefig('full_bn.png', bbox_inches='tight')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn5 = df_sar_bn4.copy()\n",
        "df_sar_bn5 = df_sar_bn5.drop(columns=['Offroad/Motor Vehicle/ATV ACTIVITY IND', 'INCIDENT REGION', 'Equipment failure CONTR FACTOR IND',\n",
        "                                      'start_month', 'Runaway ACTIVITY IND'])\n",
        "\n",
        "# check_feature_importance(df_sar_bn6, 100, 30)\n",
        "# models_and_scores5 = check_full_cv(df_sar_bn5, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hc = HillClimbSearch(df_sar_bn5, use_cache=True)\n",
        "best_model = hc.estimate(scoring_method=BicScore(df_sar_bn5), max_iter=2000000, show_progress=False)\n",
        "edges = list(best_model.edges())\n",
        "model = BayesianNetwork(edges)\n",
        "\n",
        "print(edges)\n",
        "%matplotlib inline\n",
        "\n",
        "# nx.draw(model, with_labels=True)\n",
        "plt.figure(figsize=(40, 45))\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, pos=pos, with_labels=True, node_size=3000, width=2, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='silver', font_color='black', connectionstyle='arc3,rad=0.2')\n",
        "plt.savefig('full_bn.png', bbox_inches='tight')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BicScore(df_sar_bn5).score(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn6 = df_sar_bn5.copy()\n",
        "df_sar_bn6 = df_sar_bn6.drop(columns=['Snowmobile IND', 'Dive Team IND', 'LEAD ORGANIZATION NAME'])\n",
        "\n",
        "# check_feature_importance(df_sar_bn6, 100, 30)\n",
        "# models_and_scores7 = check_full_cv(df_sar_bn6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hc = HillClimbSearch(df_sar_bn6, use_cache=True)\n",
        "best_model = hc.estimate(scoring_method=BicScore(df_sar_bn6), max_iter=2000000, show_progress=False)\n",
        "edges = list(best_model.edges())\n",
        "model = BayesianNetwork(edges)\n",
        "\n",
        "print(edges)\n",
        "%matplotlib inline\n",
        "\n",
        "# nx.draw(model, with_labels=True)\n",
        "plt.figure(figsize=(40, 45))\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, pos=pos, with_labels=True, node_size=3000, width=2, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='silver', font_color='black', connectionstyle='arc3,rad=0.2')\n",
        "plt.savefig('full_bn.png', bbox_inches='tight')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BicScore(df_sar_bn6).score(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn7 = df_sar_bn6.copy()\n",
        "df_sar_bn7 = df_sar_bn7.drop(columns=['Skiing ACTIVITY IND', 'Action IND', 'Survival Action IND'])\n",
        "\n",
        "# check_feature_importance(df_sar_bn7, 100, 30)\n",
        "# models_and_scores7 = check_full_cv(df_sar_bn7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hc = HillClimbSearch(df_sar_bn7, use_cache=True)\n",
        "best_model = hc.estimate(scoring_method=BicScore(df_sar_bn7), max_iter=2000000, show_progress=False)\n",
        "edges = list(best_model.edges())\n",
        "model = BayesianNetwork(edges)\n",
        "\n",
        "print(edges)\n",
        "%matplotlib inline\n",
        "\n",
        "# nx.draw(model, with_labels=True)\n",
        "plt.figure(figsize=(40, 45))\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, pos=pos, with_labels=True, node_size=3000, width=2, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='silver', font_color='black', connectionstyle='arc3,rad=0.2')\n",
        "plt.savefig('full_bn.png', bbox_inches='tight')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BicScore(df_sar_bn7).score(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn8 = df_sar_bn7.copy()\n",
        "df_sar_bn8 = df_sar_bn8.drop(columns=['Natural drainage ROUTE IND', 'Weather CONTR FACTOR IND', 'MAX TEMP BINNED', 'Cross country ROUTE IND', \n",
        "                                      'Did not travel ROUTE IND'])\n",
        "\n",
        "# check_feature_importance(df_sar\n",
        "hc = HillClimbSearch(df_sar_bn8, use_cache=True)\n",
        "best_model = hc.estimate(scoring_method=BicScore(df_sar_bn8), max_iter=2000000, show_progress=False)\n",
        "edges = list(best_model.edges())\n",
        "model = BayesianNetwork(edges)\n",
        "\n",
        "print(edges)\n",
        "%matplotlib inline\n",
        "\n",
        "# nx.draw(model, with_labels=True)\n",
        "plt.figure(figsize=(40, 40))\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, pos=pos, with_labels=True, node_size=3000, width=2, font_size=11,\n",
        "        arrows=True, node_color='turquoise', edge_color='silver', font_color='black', connectionstyle='arc3,rad=0.2')\n",
        "plt.savefig('full_bn.png', bbox_inches='tight')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BicScore(df_sar_bn8).score(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check_feature_selection(df_sar_bn8, 100, 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn9 = df_sar_bn8.copy()\n",
        "df_sar_bn9 = df_sar_bn9.drop(columns=['Climbing:Rock/Ice ACTIVITY IND', 'Mobile DETECT IND'])\n",
        "\n",
        "# check_feature_importance(df_sar\n",
        "hc = HillClimbSearch(df_sar_bn9, use_cache=True)\n",
        "best_model = hc.estimate(scoring_method=BicScore(df_sar_bn9), max_iter=2000000, show_progress=False)\n",
        "edges = list(best_model.edges())\n",
        "model = BayesianNetwork(edges)\n",
        "\n",
        "print(edges)\n",
        "%matplotlib inline\n",
        "\n",
        "# nx.draw(model, with_labels=True)\n",
        "plt.figure(figsize=(40, 40))\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, pos=pos, with_labels=True, node_size=3000, width=2, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='silver', font_color='black', connectionstyle='arc3,rad=0.2')\n",
        "plt.savefig('full_bn.png', bbox_inches='tight')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(23,20))\n",
        "pos = nx.circular_layout(model)\n",
        "nx.draw(model, pos=pos, with_labels=True, node_size=3000, width=1, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='black', font_color=(0.07,0.07,0.07), connectionstyle='arc3,rad=0.2')\n",
        "plt.savefig('full_bn.png', bbox_inches='tight')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BicScore(df_sar_bn9).score(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fitting the data to the model using Maximum Likelihood Estimator\n",
        "model.fit(df_sar_bn9, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "# Doing exact inference using Variable Elimination\n",
        "infer = VariableElimination(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conditional Dist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['No Medical Assistance Required', 'Required Medical Treatment', 'Deceased']:\n",
        "    print(\"CONDITION WHEN FOUND:\", i)\n",
        "    print(infer.query(variables=['FOUND IN SEARCH AREA'], evidence = {'CONDITION WHEN FOUND': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pgmpy.base import DAG\n",
        "G = DAG()\n",
        "G.add_nodes_from(nodes=['CONDITION WHEN FOUND', 'FOUND IN SEARCH AREA'])\n",
        "G.add_edge(u='CONDITION WHEN FOUND', v='FOUND IN SEARCH AREA')\n",
        "plt.figure(figsize=(12,10))\n",
        "pos = nx.circular_layout(G)\n",
        "nx.draw(G, pos=pos, with_labels=True, node_size=2000, width=1, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='black', font_color=(0.07,0.07,0.07), connectionstyle='arc3,rad=0.2')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['0-4am', '4-8am', '8am-12pm', '12-4pm', '4-8pm', '8pm-12am']:\n",
        "    print(\"start_time_interval:\", i)\n",
        "    print(infer.query(variables=['Injured SITUATION IND'], evidence = {'start_time_interval': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G = DAG()\n",
        "G.add_nodes_from(nodes=['Injured SITUATION IND', 'start_time_interval'])\n",
        "G.add_edge(u='Injured SITUATION IND', v='start_time_interval')\n",
        "G.add_edges_from(ebunch=[('Illness SITUATION IND', 'Injured SITUATION IND'), ('RESPONSE TYPE', 'Injured SITUATION IND'), ('Stranded SITUATION IND', 'Injured SITUATION IND'), ('Injured SITUATION IND', 'Darkness CONTR FACTOR IND')])\n",
        "plt.figure(figsize=(10,6))\n",
        "pos = nx.circular_layout(G)\n",
        "nx.draw(G, pos=pos, with_labels=True, node_size=2000, width=1, font_size=11,\n",
        "        arrows=True, node_color='skyblue', edge_color='black', font_color=(0.07,0.07,0.07), connectionstyle='arc3,rad=0.2')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['Yes', 'No']:\n",
        "    print(\"Injured SITUATION IND:\", i)\n",
        "    print(infer.query(variables=['start_time_interval'], evidence = {'Injured SITUATION IND': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['0-4am', '4-8am', '8am-12pm', '12-4pm', '4-8pm', '8pm-12am']:\n",
        "    print(\"start_time_interval:\", i)\n",
        "    print(infer.query(variables=['RESPONSE TYPE'], evidence = {'start_time_interval': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['Yes', 'No']:\n",
        "    print(\"Darkness CONTR FACTOR IND:\", i)\n",
        "    print(infer.query(variables=['Injured SITUATION IND'], evidence = {'Darkness CONTR FACTOR IND': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['Recovery', 'Rescue', 'Search']:\n",
        "    print(\"RESPONSE TYPE:\", i)\n",
        "    print(infer.query(variables=['Injured SITUATION IND'], evidence = {'RESPONSE TYPE': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['0% M', '1-49% M', '50% M', '51-99% M', '100% M']:\n",
        "    print(\"Prop M Subjects Binned:\", i)\n",
        "    print(infer.query(variables=['Assist/own power IND'], evidence = {'Prop M Subjects Binned': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G = DAG()\n",
        "G.add_edges_from(ebunch=[('Missing SITUATION IND', 'Dementia IND'), ('Land Class', 'Missing SITUATION IND'), ('CONDITION WHEN FOUND', 'Missing SITUATION IND'), ('Missing SITUATION IND', 'Aircraft/Helicopter/UAV IND'), ('Aircraft/Helicopter/UAV IND', 'NUMBER RANGERS BINNED')])\n",
        "plt.figure(figsize=(14,6))\n",
        "pos = nx.circular_layout(G)\n",
        "nx.draw(G, pos=pos, with_labels=True, node_size=4000, width=1, font_size=12,\n",
        "        arrows=True, node_color='skyblue', edge_color='black', font_color=(0.07,0.07,0.07), connectionstyle='arc3,rad=0.2')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['Yes', 'No']:\n",
        "    print(\"Missing SITUATION IND:\", i)\n",
        "    print(infer.query(variables=['Land Class'], evidence = {'Missing SITUATION IND': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['Yes', 'No']:\n",
        "    print(\"Dementia IND:\", i)\n",
        "    print(infer.query(variables=['Missing SITUATION IND'], evidence = {'Dementia IND': i}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in ['Yes', 'No']:\n",
        "    print(\"Missing SITUATION IND':\", i)\n",
        "    print(infer.query(variables=['Aircraft/Helicopter/UAV IND'], evidence = {'Missing SITUATION IND': i}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Counterfactual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(infer.query(variables=['Injured SITUATION IND'], evidence = {'Darkness CONTR FACTOR IND': 'Yes'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(infer.query(variables=['Injured SITUATION IND'], evidence = {'Darkness CONTR FACTOR IND': 'No'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from pgmpy.inference import CausalInference\n",
        "causal_infer = CausalInference(model)\n",
        "# causal_infer.query(['Injured SITUATION IND'], do={'Terrain CONTR FACTOR IND': 'No'}, evidence={'Darkness CONTR FACTOR IND': 'Yes'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(causal_infer.query(['Total Subjects Binned'], do={'Injured SITUATION IND': 'Yes'}, evidence={'Prop M Subjects Binned': '100% M'}))\n",
        "print(causal_infer.query(['Total Subjects Binned'], do={'Injured SITUATION IND': 'No'}, evidence={'Prop M Subjects Binned': '100% M'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(causal_infer.query(['CONDITION WHEN FOUND'], do={'Missing SITUATION IND': 'Yes'}))\n",
        "print(causal_infer.query(['CONDITION WHEN FOUND'], do={'Missing SITUATION IND': 'No'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(causal_infer.query(['NUMBER RANGERS BINNED'], do={'Missing SITUATION IND': 'Yes'}))\n",
        "print(causal_infer.query(['NUMBER RANGERS BINNED'], do={'Missing SITUATION IND': 'No'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(causal_infer.query(['Darkness CONTR FACTOR IND'], do={'Stranded SITUATION IND': 'Yes'}))\n",
        "print(causal_infer.query(['Darkness CONTR FACTOR IND'], do={'Stranded SITUATION IND': 'No'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(causal_infer.query(['Prop M Subjects Binned'], do={'Assist/own power IND': 'Yes'}, evidence={'Missing SITUATION IND': 'Yes'}))\n",
        "print(causal_infer.query(['Prop M Subjects Binned'], do={'Assist/own power IND': 'No'}, evidence={'Missing SITUATION IND': 'Yes'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(causal_infer.query(['Prop M Subjects Binned'], do={'Injured SITUATION IND': 'Yes'}))\n",
        "print(causal_infer.query(['Prop M Subjects Binned'], do={'Injured SITUATION IND': 'No'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pickle Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bn_full_pickle = open('bn_full.pickle', 'wb') \n",
        "\n",
        "# Write DT model to the file\n",
        "pickle.dump(model, bn_full_pickle) \n",
        "\n",
        "# Close the file\n",
        "bn_full_pickle.close() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sar_bn9['Land Class'].value_counts()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
